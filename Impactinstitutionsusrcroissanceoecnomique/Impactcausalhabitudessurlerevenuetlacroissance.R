# Chemin vers le fichier de donn√©es
file_path <- "C:/Users/grego/OneDrive/Documents/sampled_data1.csv"
output_path <- "C:/Users/grego/OneDrive/Documents/pooled_model_summary.txt"
library(readr)
library(data.table)




# Charger les biblioth√®ques n√©cessaires
library(plm)
library(dplyr)
library(readr)

# Charger les donn√©es
cat("Chargement des donn√©es...\n")
data <- read_csv(file_path)


##Parties descriptives. 



cat("Aper√ßu des donn√©es avant traitement :\n")
print(head(data))

# Filtrer les variables explicatives X
x_variables <- c("VEGMO", "ORANGYR", "FRUITMO", "BREAKFAST", 
                 "SNACKS", "HRSLEEP", "VIG10DMIN", "EDUC")
if (!all(x_variables %in% colnames(data))) {
  stop("Certaines variables explicatives manquent dans les donn√©es.")
}
y_variable <-c("EARNIMP4")



library("dplyr")
#Transformer notamment pour la variable FRUTNO 
library(dplyr)

# Remplacer les valeurs sp√©cifiques par NA
library(dplyr)

# Remplacer les valeurs 996, 997, 998, 999 par NA dans frutno et vegeno
data <- data %>%
  mutate(across(c(FRUTNO, VEGENO), ~ ifelse(. %in% c(996, 997, 998, 999), NA, .)))

# V√©rifier les changements
table(data$FRUTNO, useNA = "always")  # V√©rifier pour frutno
table(data$VEGENO, useNA = "always")  # V√©rifier pour vegeno


###Pour VIG10DMIN : 
library(dplyr)

# Remplacer les valeurs sp√©cifiques par NA dans vig10
data <- data %>%
  mutate(VIG10DMIN = ifelse(VIG10DMIN %in% c(997, 998, 999), NA, VIG10DMIN))

# V√©rifier les changements
table(data$VIG10DMIN, useNA = "always")  # V√©rifier si les NA sont bien int√©gr√©s

###Point sur le nombre de valeurs manquantes par donn√©es. 
colSums(is.na(data))
nrow(data)

# Calculer le pourcentage de valeurs manquantes par colonne
missing_percent <- colSums(is.na(data)) / nrow(data) * 100

# Afficher les colonnes tri√©es par pourcentage de valeurs manquantes
sort(missing_percent, decreasing = TRUE)


####Transformer la variable EDUCation ici en ann√©es : 
library(dplyr)

library(dplyr)

# Recodification des codes d'√©ducation en ann√©es de scolarit√© (+1 ann√©e)
data <- data %>%
  mutate(EDUC = case_when(
    EDUC == 102 ~ "Maternelle",  # Kindergarten seulement -> 1 an
    EDUC == 104 ~ "CP",  # Grade 1 -> 1+1 = 2 ans
    EDUC == 105 ~ "CE1",  # Grade 2 -> 2+1 = 3 ans
    EDUC == 106 ~ "CE2",  # Grade 3 -> 3+1 = 4 ans
    EDUC == 107 ~ "CM1",  # Grade 4 -> 4+1 = 5 ans
    EDUC == 108 ~ "CM2",  # Grade 5 -> 5+1 = 6 ans
    EDUC == 109 ~ "6eme",  # Grade 6 -> 6+1 = 7 ans
    EDUC == 110 ~ "5eme",  # Grade 7 -> 7+1 = 8 ans
    EDUC == 111 ~ "4eme",  # Grade 8 -> 8+1 = 9 ans
    EDUC == 113 ~ "3eme", # Grade 9 -> 9+1 = 10 ans
    EDUC == 114 ~ "Seconde", # Grade 10 -> 10+1 = 11 ans
    EDUC == 115 ~ "Premiere", # Grade 11 -> 11+1 = 12 ans
    EDUC == 116 ~ "Bacrate", # Grade 12 (pas de dipl√¥me) -> 12+1 = 13 ans
    EDUC == 200 ~ "Lycee", # Dipl√¥me de secondaire (High school) -> 12+1 = 13 ans
    EDUC == 201 ~ "Lyceeadulte", # Dipl√¥m√© du secondaire -> 12+1 = 13 ans
    EDUC == 202 ~ "13", # GED ou √©quivalent -> 12+1 = 13 ans
    EDUC == 300 ~ "1ereanneeuniv", # 1√®re ann√©e d'universit√© -> 13+1 = 14 ans
    EDUC == 301 ~ "14", # 1-3 ans d'universit√© -> 13+1 = 14 ans
    EDUC == 302 ~ "Bac2technique", # Dipl√¥me technique (AA degree) -> 14+1 = 15 ans
    EDUC == 303 ~ "Bac2univ", # Dipl√¥me acad√©mique (AA degree) -> 14+1 = 15 ans
    EDUC == 400 ~ "Bachelor", # Licence (Bachelor's degree) -> 16+1 = 17 ans
    EDUC == 501 ~ "Master", # Master -> 18+1 = 19 ans
    EDUC == 502 ~ "EcolePro", # √âcole professionnelle (MD, JD, etc.) -> 20+1 = 21 ans
    EDUC == 503 ~ "Doctorat", # Doctorat (PhD, EdD) -> 20+1 = 21 ans
    EDUC == 505 ~ "Doctoratpro", # Doctorat/√âcole professionnelle (top) -> 20+1 = 21 ans
    EDUC %in% c(996, 997, 998, 999) ~ NA_character_, # Cas inconnus -> NA
    TRUE ~ NA_character_ # Autres cas inconnus -> NA
  ))
colnames(data)  # Liste toutes les colonnes g√©n√©r√©es

# Affichage du tableau mis √† jour
print(data)




###Traitemetn de  l'√©ducation en dummies 
library(dplyr)
library(fastDummies)

data <- data %>%
  mutate(EDUC = factor(EDUC)) %>%  # Convertir en facteur si ce n'est pas d√©j√† fait
  dummy_cols(select_columns = "EDUC", remove_selected_columns = FALSE)

###Ainsi la liste des dummys est la suivante , en enlevant la maternelle. 
# EDUC_CP + EDUC_CE1 + EDUC_CE2 + EDUC_CM1 + EDUC_CM2 + EDUC_6eme + EDUC_5eme + EDUC_4eme + EDUC_3eme + EDUC_Seconde + EDUC_Premiere + EDUC_Bacrat√© + EDUC_Lyc√©e + EDUC_Lyc√©eadulte + EDUC_13 + EDUC_1ereann√©euniv + EDUC_14 + EDUC_Bac+2technique + EDUC_Bac+2univ + EDUC_Bachelor + EDUC_Master + EDUC_EcolePro + EDUC_Doctorat + EDUC_Doctoratpro


###Transformation de sexe en dummies 

###DUmmys pour sexe

# Installer et charger le package
library(fastDummies)

# Supposons que votre data frame s'appelle 'data'
# Cr√©er des variables dummy pour la colonne 'sex'
data <- dummy_cols(data, select_columns = "SEX", remove_first_dummy = TRUE)


####Traitement de EARNIMP4 et notamment sa transformation en variable continue. 

library(dplyr)


# Recodification en valeur continue (valeur m√©diane de chaque tranche)
data <- data %>%
  mutate(EARNIMP4 = case_when(
    EARNIMP4 == 1  ~ 2500,   # $1 - $4,999 -> M√©diane = $2,500
    EARNIMP4 == 2  ~ 7500,   # $5,000 - $9,999 -> M√©diane = $7,500
    EARNIMP4 == 3  ~ 12500,  # $10,000 - $14,999 -> M√©diane = $12,500
    EARNIMP4 == 4  ~ 17500,  # $15,000 - $19,999 -> M√©diane = $17,500
    EARNIMP4 == 5  ~ 22500,  # $20,000 - $24,999 -> M√©diane = $22,500
    EARNIMP4 == 10 ~ 30000,  # $25,000 - $34,999 -> M√©diane = $30,000
    EARNIMP4 == 11 ~ 27500,  # $25,000 - $29,999 -> M√©diane = $27,500
    EARNIMP4 == 12 ~ 32500,  # $30,000 - $34,999 -> M√©diane = $32,500
    EARNIMP4 == 20 ~ 40000,  # $35,000 - $44,999 -> M√©diane = $40,000
    EARNIMP4 == 21 ~ 37500,  # $35,000 - $39,999 -> M√©diane = $37,500
    EARNIMP4 == 22 ~ 42500,  # $40,000 - $44,999 -> M√©diane = $42,500
    EARNIMP4 == 30 ~ 50000,  # $45,000 - $54,999 -> M√©diane = $50,000
    EARNIMP4 == 31 ~ 47500,  # $45,000 - $49,999 -> M√©diane = $47,500
    EARNIMP4 == 32 ~ 52500,  # $50,000 - $54,999 -> M√©diane = $52,500
    EARNIMP4 == 40 ~ 60000,  # $55,000 - $64,999 -> M√©diane = $60,000
    EARNIMP4 == 41 ~ 57500,  # $55,000 - $59,999 -> M√©diane = $57,500
    EARNIMP4 == 42 ~ 62500,  # $60,000 - $64,999 -> M√©diane = $62,500
    EARNIMP4 == 50 ~ 70000,  # $65,000 - $74,999 -> M√©diane = $70,000
    EARNIMP4 == 51 ~ 67500,  # $65,000 - $69,999 -> M√©diane = $67,500
    EARNIMP4 == 52 ~ 72500,  # $70,000 - $74,999 -> M√©diane = $72,500
    EARNIMP4 == 60 ~ 85000,  # $75,000 et plus -> Estim√© √† $85,000
    EARNIMP4 == 61 ~ 77500,  # $75,000 - $79,999 -> M√©diane = $77,500
    EARNIMP4 == 62 ~ 82500,  # $80,000 - $84,999 -> M√©diane = $82,500
    EARNIMP4 == 63 ~ 87500,  # $85,000 - $89,999 -> M√©diane = $87,500
    EARNIMP4 == 64 ~ 92500,  # $90,000 - $94,999 -> M√©diane = $92,500
    EARNIMP4 == 65 ~ 97500,  # $95,000 - $99,999 -> M√©diane = $97,500
    EARNIMP4 == 66 ~ 110000, # $100,000 et plus -> Estim√© √† $110,000
    EARNIMP4 == 67 ~ 102500, # $100,000 - $104,999 -> M√©diane = $102,500
    EARNIMP4 == 68 ~ 107500, # $105,000 - $109,999 -> M√©diane = $107,500
    EARNIMP4 == 69 ~ 112500, # $110,000 - $114,999 -> M√©diane = $112,500
    EARNIMP4 == 70 ~ 120000, # $115,000 et plus -> Estim√© √† $120,000
    EARNIMP4 %in% c(97, 98, 99) ~ NA_real_,  # Valeurs inconnues
    TRUE ~ NA_real_
  ))

# Affichage du dataset recod√©
print(data)







###Traitement des valeurs manquantes 

# Remplacement des valeurs manquantes par la m√©diane pour les colonnes num√©riques
cat("Remplacement des valeurs manquantes par la m√©diane...\n")
data <- data %>%
  mutate(across(where(is.numeric), ~ ifelse(is.na(.), median(., na.rm = TRUE), .)))

# Convertir SERIAL et YEAR en facteurs
data <- data %>%
  mutate(SERIAL = as.factor(SERIAL),
         YEAR = as.factor(YEAR)) 
# Identifier et g√©rer les duplications
cat("Recherche des duplications...\n")
duplicates <- data %>%
  group_by(SERIAL, YEAR) %>%
  filter(n() > 1)

if (nrow(duplicates) > 0) {
  cat("Doublons d√©tect√©s dans SERIAL et YEAR. Voici un aper√ßu :\n")
  print(duplicates)
  
  # Supprimer les duplications en gardant la premi√®re occurrence
  data <- data %>%
    distinct(SERIAL, YEAR, .keep_all = TRUE)
  cat("Les duplications ont √©t√© supprim√©es.\n")
} else {
  cat("Aucune duplication d√©tect√©e.\n")
}


###Partie √©ducation en dummies. 

summary(data)


###Partie normalisation pour data 1

# Normalisation (Z-score) de Y et des X
cat("Normalisation des donn√©es (Z-score)...\n")
data1 <- data %>%
  mutate(
    across(all_of(c(y_variable, x_variables)), ~ (.-mean(., na.rm = TRUE)) / sd(., na.rm = TRUE))
  )



###GENERALE pour la formule : arr√™t ici : avec cr√©ation panel et formule r√©utilisable

# Cr√©er un DataFrame panel (index√© par SERIAL et YEAR)
pdata <- pdata.frame(data, index = c("SERIAL", "YEAR"))

# Formule de r√©gression EDUC 6 ENLEVE 
formula <- log(EARNIMP4) ~ VEGENO + ORANGYR + FRUTNO + BREAKFAST + SNACKS + HRSLEEP + VIG10DMIN + AGE + I(AGE^2) + SEX + EDUC_13 + EDUC_14 + EDUC_3eme + EDUC_4eme + EDUC_5eme  + EDUC_Bac2technique + EDUC_Bac2univ + EDUC_Bachelor + EDUC_Bacrate + EDUC_CE1 + EDUC_CE2 + EDUC_CM1 + EDUC_CM2 + EDUC_CP + EDUC_Doctorat + EDUC_Doctoratpro + EDUC_EcolePro + EDUC_Lyceeadulte + EDUC_Master + EDUC_Maternelle + EDUC_Premiere + EDUC_Seconde 

###

# Ajuster le mod√®le Pooled OLS
cat("Ajustement du mod√®le Pooled OLS...\n")
pooled_model <- tryCatch({
  plm(formula, data = pdata, model = "pooling")
}, error = function(e) {
  stop("Erreur lors de l'ajustement du mod√®le :", e$message)
})


library(plm)       # Mod√®les de panel (Between, Within, Random)
library(stargazer) # R√©sum√© des mod√®les en tableau
library(car)       # Calcul du VIF
library(nlme)      # Mod√®le FE-GLS et FGLS


# R√©sultat final
cat("R√©sum√© du mod√®le Pooled OLS :\n")
print(summary(pooled_model))

#Tentons avec la premi√®re imputation du salaire et voyons si les r√©sultats s'am√©liorent. 

# Formule de r√©gression
formula <- EARNIMP4 ~ VEGNO + ORANGYR + FRUTNO + BREAKFAST + 
  SNACKS + HRSLEEP + VIG10DMIN + EDUC

# Ajuster le mod√®le Pooled OLS
cat("Ajustement du mod√®le Pooled OLS...\n")
pooled_model <- tryCatch({
  plm(formula, data = pdata, model = "pooling")
}, error = function(e) {
  stop("Erreur lors de l'ajustement du mod√®le :", e$message)
})

# R√©sultat final
cat("R√©sum√© du mod√®le Pooled OLS :\n")
print(summary(pooled_model))


#2eme EARNIMP : 

# Formule de r√©gression
formula <- EARNIMP1 ~ VEGMO + ORANGYR + FRUITMO + BREAKFAST + 
  SNACKS + HRSLEEP + VIG10DMIN + EDUC

# Ajuster le mod√®le Pooled OLS
cat("Ajustement du mod√®le Pooled OLS...\n")
pooled_model <- tryCatch({
  plm(formula, data = pdata, model = "pooling")
}, error = function(e) {
  stop("Erreur lors de l'ajustement du mod√®le :", e$message)
})

# R√©sultat final
cat("R√©sum√© du mod√®le Pooled OLS :\n")
print(summary(pooled_model))
#2eme earnimp : 2eme type d'imputations manquantes 


# Formule de r√©gression
formula <- EARNIMP2 ~ VEGMO + ORANGYR + FRUITMO + BREAKFAST + 
  SNACKS + HRSLEEP + VIG10DMIN + EDUC

# Ajuster le mod√®le Pooled OLS
cat("Ajustement du mod√®le Pooled OLS...\n")
pooled_modelIMP2 <- tryCatch({
  plm(formula, data = pdata, model = "pooling")
}, error = function(e) {
  stop("Erreur lors de l'ajustement du mod√®le :", e$message)
})

# R√©sultat final
cat("R√©sum√© du mod√®le Pooled OLS :\n")
print(summary(pooled_modelIMP2))

#3eme earnimp : 
# Formule de r√©gression
formula <- EARNIMP3 ~ VEGMO + ORANGYR + FRUITMO + BREAKFAST + 
  SNACKS + HRSLEEP + VIG10DMIN + EDUC

# Ajuster le mod√®le Pooled OLS
cat("Ajustement du mod√®le Pooled OLS...\n")
pooled_modelIMP3 <- tryCatch({
  plm(formula, data = pdata, model = "pooling")
}, error = function(e) {
  stop("Erreur lors de l'ajustement du mod√®le :", e$message)
})

# R√©sultat final
cat("R√©sum√© du mod√®le Pooled OLS :\n")
print(summary(pooled_modelIMP3))

#4eme m√©thode de EARNIMP4 : 


# Formule de r√©gression
formula <- EARNIMP4 ~ VEGMO + ORANGYR + FRUITMO + BREAKFAST + 
  SNACKS + HRSLEEP + VIG10DMIN + EDUC

# Ajuster le mod√®le Pooled OLS
cat("Ajustement du mod√®le Pooled OLS...\n")
pooled_modelIMP4 <- tryCatch({
  plm(formula, data = pdata, model = "pooling")
}, error = function(e) {
  stop("Erreur lors de l'ajustement du mod√®le :", e$message)
})

# R√©sultat final
cat("R√©sum√© du mod√®le Pooled OLS :\n")
print(summary(pooled_modelIMP4))


# Formule de r√©gression
formula <- EARNIMP5 ~ VEGMO + ORANGYR + FRUITMO + BREAKFAST + 
  SNACKS + HRSLEEP + VIG10DMIN + EDUC

# Ajuster le mod√®le Pooled OLS
cat("Ajustement du mod√®le Pooled OLS...\n")
pooled_modelIMP5 <- tryCatch({
  plm(formula, data = pdata, model = "pooling")
}, error = function(e) {
  stop("Erreur lors de l'ajustement du mod√®le :", e$message)
})

# R√©sultat final
cat("R√©sum√© du mod√®le Pooled OLS :\n")
print(summary(pooled_modelIMP5))

stargazer(pooled_model,pooled_modelIMP2,pooled_modelIMP3,pooled_modelIMP4,pooled_modelIMP5)

export_results <- function(model, output_path) {
  # Exporter les r√©sultats dans un fichier
  if (!is.null(model)) {
    tryCatch({
      summary_text <- capture.output(summary(model))
      writeLines(summary_text, con = output_path)
      cat(sprintf("\nR√©sum√© export√© avec succ√®s vers %s\n", output_path))
    }, error = function(e) {
      cat(sprintf("Erreur lors de l'exportation : %s\n", e$message))
    })
  } else {
    cat("Aucun mod√®le √† exporter.\n")
  }
}

# Ex√©cution principale
pooled_model <- run_log_model(file_path)
export_results(pooled_model, output_path)

#####Nouveuax modeles : 
# Charger le package n√©cessaire
library(nlme)

# Ajuster le mod√®le GLS
gls_model <- tryCatch({
  gls(formula, data = pdata, method = "REML")
}, error = function(e) {
  stop("Erreur lors de l'ajustement du mod√®le GLS :", e$message)
})

# R√©sum√© du mod√®le GLS
summary(gls_model)

###Nouveau modele GLS : 
# Charger le package n√©cessaire
library(nlme)

# Ajuster le mod√®le GLS avec structure de corr√©lation et h√©t√©rosc√©dasticit√©
gls_model <- tryCatch({
  gls(formula, data = pdata, 
      correlation = corAR1(form = ~ 1 | SERIAL),  # Structure de corr√©lation AR(1) pour les individus # Gestion de l'h√©t√©rosc√©dasticit√© par groupe
      method = "REML")
}, error = function(e) {
  stop("Erreur lors de l'ajustement du mod√®le GLS :", e$message)
})

# R√©sum√© du mod√®le GLS
summary(gls_model)

# Calcul du pseudo-R¬≤ de Nagelkerke (variance expliqu√©e)
R2_gls <- 1 - (gls_model$sigma^2 / var(pdata$EARNIMP4))

cat("Pseudo-R¬≤ de Nagelkerke:", R2_gls, "\n")



####Utiliser les valeurs imput√©es pour les revenus personnels : un changement dans le R2 ? 

# Convertir SERIAL et YEAR en facteurs
data <- data %>%
  mutate(SERIAL = as.factor(SERIAL),
         YEAR = as.factor(YEAR))


# Variables explicatives
x_variables <- c("VEGMO", "ORANGYR", "FRUITMO", "BREAKFAST", 
                 "SNACKS", "HRSLEEP", "VIG10DMIN", "EDUC", "AGE", "SEX")

# Variables d√©pendantes √† tester
earnimp_vars <- c("EARNIMP1", "EARNIMP2", "EARNIMP3", "EARNIMP4", "EARNIMP5")

# Liste pour stocker les mod√®les
models <- list()

# Ajuster un mod√®le pour chaque variable d√©pendante
for (var in earnimp_vars) {
  # Construire la formule de r√©gression
  formula <- as.formula(paste(var, "~", paste(x_variables, collapse = " + ")))
  
  # Ajustement du mod√®le Pooled OLS
  cat(sprintf("Ajustement du mod√®le Pooled OLS pour la variable %s...\n", var))
  pooled_model <- tryCatch({
    plm(formula, data = pdata, model = "pooling")
  }, error = function(e) {
    stop(sprintf("Erreur lors de l'ajustement du mod√®le pour %s : %s", var, e$message))
  })
  
  # Stocker le mod√®le
  models[[var]] <- pooled_model
}

# Exporter les r√©sultats avec stargazer
jpeg("C:/Users/grego/OneDrive/Documents/pooled_model_results.jpeg", width = 1000, height = 800)
stargazer(models, type = "text", title = "R√©sultats des mod√®les Pooled OLS", align = TRUE)
dev.off()

cat("\nLes r√©sultats ont √©t√© export√©s au format JPEG dans le fichier sp√©cifi√©.\n")

###R√©gression sur le EARNIMP4 avec le logarithme. 


####Cherchons le meilleur mod√®le l'exhaustive search. 

# Charger les biblioth√®ques n√©cessaires
library(plm)
library(dplyr)
library(readr)
library(leaps)
library(stargazer)


# Variables explicatives (incluant AGE et SEX)
x_variables <- c("VEGMO", "ORANGYR", "FRUITMO", "BREAKFAST", 
                 "SNACKS", "HRSLEEP", "VIG10DMIN", "EDUC", "AGE", "SEX")

# Variable d√©pendante
y_variable <- "EARNIMP4"



# Pr√©parer les donn√©es pour la s√©lection exhaustive
temp_data <- data %>% select(all_of(c(y_variable, x_variables))) %>% na.omit()

# Effectuer la s√©lection exhaustive
exhaustive_search <- regsubsets(as.formula(paste(y_variable, "~ .")), 
                                data = temp_data, 
                                nvmax = length(x_variables))

# R√©sum√© des mod√®les ajust√©s
model_summary <- summary(exhaustive_search)

# Trouver le mod√®le avec le meilleur R¬≤ ajust√©
best_model_index <- which.max(model_summary$adjr2)

# Extraire les variables s√©lectionn√©es
best_variables <- names(which(model_summary$which[best_model_index, -1]))

# Construire la formule avec les meilleures variables
best_formula <- as.formula(paste(y_variable, "~", paste(best_variables, collapse = " + ")))

# Ajuster le mod√®le Pooled OLS avec les meilleures variables
cat("Ajustement du mod√®le Pooled OLS avec les meilleures variables...\n")
best_pooled_model <- plm(best_formula, data = pdata, model = "pooling")

# R√©sultat final
cat("R√©sum√© du mod√®le s√©lectionn√© :\n")
print(summary(best_pooled_model))

# Exporter les r√©sultats avec stargazer
jpeg("C:/Users/grego/OneDrive/Documents/pooled_model_best_results.jpeg", width = 1000, height = 800)
stargazer(best_pooled_model, type = "text", title = "Meilleur mod√®le Pooled OLS avec EARNIMP4")
dev.off()

cat("\nLes r√©sultats du meilleur mod√®le ont √©t√© export√©s au format JPEG.")

#Ainsi, si l'on souhaite le mod√®le avec le meilleur R2, il faudrait toutefois supprimer la variable VEGENO. 


#Cr√©ons la transformation de r√™ve : le logarithme. 

# Filtrer les observations avec EARNIMP4 > 0
pdata <- pdata[pdata$EARNIMP4 > 0 & !is.na(pdata$EARNIMP4), ]

# Formule de r√©gression (avec VEGMO et log(EARNIMP4))
formula <- log(EARNIMP4) ~ VEGMO + ORANGYR + FRUITMO + BREAKFAST + 
  SNACKS + HRSLEEP + VIG10DMIN + EDUC

# Ajuster le mod√®le Pooled OLS
cat("Ajustement du mod√®le Pooled OLS avec log(EARNIMP4)...\n")
pooled_modelIMP4 <- tryCatch({
  plm(formula, data = pdata, model = "pooling")
}, error = function(e) {
  stop("Erreur lors de l'ajustement du mod√®le :", e$message)
})

# R√©sultat final
cat("R√©sum√© du mod√®le Pooled OLS :\n")
print(summary(pooled_modelIMP4))

#En comparant les mod√®les, la suppression de VEGMO, fait diminuer la valeur d'impact
#de manger un fruit de 3%. Ainsi, on pouvait souligner un probl√®me de variable omise. 
#Cela pourrait s'expliquer par l'abus de sucre potentiellement. 
#Augmenter de 1 unit√© dans FRUITMO, correspond √† environ 30 fruits de plus dans l'ann√©e. 
#Ainsi, en moyenne, cela diminuerait de 10% le salaire. 
#Fruitmo , en g√©n√©ral, en lien potentiellement avec le sucre, pourrait √™tre



#On va donc ajouter la variable SWEET afin d'avoir plus de recul. sur notre analyse. 


# Formule de r√©gression (sans VEGMO et log(EARNIMP4))
formula <- log(EARNIMP4) ~  + ORANGYR + FRUITMO + BREAKFAST + 
  SNACKS + HRSLEEP + VIG10DMIN + EDUC

# Ajuster le mod√®le Pooled OLS
cat("Ajustement du mod√®le Pooled OLS avec log(EARNIMP4)...\n")
pooled_modelLIN <- tryCatch({
  plm(formula, data = pdata, model = "pooling")
}, error = function(e) {
  stop("Erreur lors de l'ajustement du mod√®le :", e$message)
})

# R√©sultat final
cat("R√©sum√© du mod√®le Pooled OLS :\n")
print(summary(pooled_modelLIN))


####7  : comparer entre tous les mod√®les de panel 


# D√©finition de la formule initiale
formula <- EARNIMP4 ~ BREAKFAST + HRSLEEP + EDUC + MOD10DMIN + VEGENO + SEX + I(AGE^2) + AGE 

# Fonction pour ajuster le mod√®le et v√©rifier le VIF
reduce_multicollinearity <- function(data, formula, vif_threshold = 10) {
  
  # Convertir la formule en une liste de variables
  vars <- all.vars(formula)
  dependent_var <- vars[1]  # Variable d√©pendante
  independent_vars <- vars[-1]  # Variables explicatives
  
  # Boucle pour √©liminer les variables √† VIF √©lev√©
  while (TRUE) {
    # Ajuster le mod√®le Between Effects (BE)
    be_model <- plm(as.formula(paste(dependent_var, "~", paste(independent_vars, collapse = " + "))),
                    data = data, model = "between", effect = "time")
    
    # Calculer le VIF
    vif_values <- vif(be_model)
    
    # V√©rifier si tous les VIF sont inf√©rieurs au seuil
    if (all(vif_values < vif_threshold)) {
      cat("\n‚úÖ Toutes les variables ont un VIF < ", vif_threshold, "\n")
      break
    }
    
    # Trouver la variable avec le plus grand VIF
    max_vif_var <- names(vif_values)[which.max(vif_values)]
    cat("\nüö® Suppression de la variable :", max_vif_var, "avec VIF =", max(vif_values), "\n")
    
    # Supprimer cette variable de la liste
    independent_vars <- setdiff(independent_vars, max_vif_var)
    
    # V√©rifier qu'il reste au moins une variable explicative
    if (length(independent_vars) == 0) {
      cat("\n‚ùå Plus de variables explicatives disponibles ! Arr√™t.\n")
      break
    }
  }
  
  # Retourner la nouvelle formule optimis√©e
  return(as.formula(paste(dependent_var, "~", paste(independent_vars, collapse = " + "))))
}

# Ex√©cuter la fonction sur les donn√©es pdata
optimized_formula <- reduce_multicollinearity(pdata, formula)

# Afficher la formule finale apr√®s r√©duction de la multicolin√©arit√©
cat("\nüîπ Nouvelle formule optimis√©e :", deparse(optimized_formula), "\n")


# V√©rification des donn√©es panel
library(plm)
if (!"pdata.frame" %in% class(pdata)) {
  pdata <- pdata.frame(pdata, index = c("serial", "year"))  # Remplacez "id" et "time" par vos colonnes d'index
}

####2eme v√©rification
# Test d'alias (multicolin√©arit√© parfaite)
alias(lm(EARNIMP4 ~ BREAKFAST + HRSLEEP + EDUC + MOD10DMIN + VEGENO + SEX + I(AGE^2) + AGE, data = pdata))

###2eme test :
# S√©lection des variables explicatives sous forme de matrice
X <- model.matrix(~ BREAKFAST + HRSLEEP + EDUC + MOD10DMIN + VEGENO + SEX + I(AGE^2) + AGE, data = pdata)

# D√©composition en valeurs singuli√®res
svd_decomp <- svd(X)

# Affichage des valeurs singuli√®res
print(svd_decomp$d)

# V√©rification de la condition number (plus le ratio max/min est grand, plus il y a de multicolin√©arit√©)
condition_number <- max(svd_decomp$d) / min(svd_decomp$d)
print(condition_number)



### Partie RESTE !


# Formule de r√©gression EDUC 6 ENLEVE 
formula <- log(EARNIMP4) ~ VEGENO + ORANGYR  + BREAKFAST + HRSLEEP + VIG10DMIN + AGE + I(AGE^2) + SEX + EDUC_13 + EDUC_14 + EDUC_3eme + EDUC_4eme + EDUC_5eme  + EDUC_Bac2technique + EDUC_Bac2univ + EDUC_Bachelor + EDUC_Bacrate + EDUC_CE1 + EDUC_CE2 + EDUC_CM1 + EDUC_CM2 + EDUC_CP + EDUC_Doctorat + EDUC_Doctoratpro + EDUC_EcolePro + EDUC_Lyceeadulte + EDUC_Master + EDUC_Maternelle + EDUC_Premiere + EDUC_Seconde 



# Pooled OLS
cat("Ajustement du mod√®le Pooled OLS avec log(EARNIMP4)...\n")
pooled_modelLIN <- plm(formula, data = pdata, model = "pooling")
cat("R√©sum√© du mod√®le Pooled OLS :\n")
print(summary(pooled_modelLIN))




# Fixed Effects (FE)
cat("\nAjustement du mod√®le Fixed Effects (FE) avec log(EARNIMP4)...\n")
fe_modelLIN <- plm(formula, data = pdata, model = "within",effect="twoways")
summary(fe_modelLIN)
cat("R√©sum√© du mod√®le Fixed Effects :\n")
coeftest(fe_modelLIN, vcov = vcovHC(fe_modelLIN, type = "HC0", cluster = "group"))

print(summary(fe_modelLIN))
pFtest(fe_modelLIN,pooled_modelLIN)
bptest(fe_modelLIN)
library(stargazer)
stargazer(pooled_modelLIN,fe_modelLIN,be_modelTIME,re_modelLIN,type = "text", title = "Mod√®les de Panel")


library(sandwich)
coeftest(fe_modelLIN, vcov = vcovHAC(fe_modelLIN))



cat("\nAjustement du mod√®le Fixed Effects (FE) avec log(EARNIMP4)...\n")
fe_modelLIN <- plm(formula, data = pdata, model = "within", effect="time")
cat("R√©sum√© du mod√®le Fixed Effects :\n")
print(summary(fe_modelLIN))

pFtest(fe_modelLIN,pooled_modelLIN)

#Effect individuel
cat("\nAjustement du mod√®le Fixed Effects (FE) avec log(EARNIMP4)...\n")
fe_modelLIN <- plm(formula, data = pdata, model = "within", effect="twoways")
cat("R√©sum√© du mod√®le Fixed Effects :\n")
print(summary(fe_modelLIN))
library(sandwich)
library(lmtest)
coeftest(fe_modelLIN, vcov = vcovHC(fe_modelLIN, type = "HC0"))
coeftest(fe_modelLIN, vcov = vcovHC(fe_modelLIN, type = "HC0", cluster = "time"))

pFtest(fe_modelLIN,pooled_modelLIN)


phtest(fe_modelLIN, be_modelLIN)
# Random Effects (RE)
cat("\nAjustement du mod√®le Random Effects (RE) avec log(EARNIMP4)...\n")
re_modelLIN <- plm(formula, data = pdata, model = "random")
cat("R√©sum√© du mod√®le Random Effects :\n")
print(summary(re_modelLIN))

# Random Effects (RE)
cat("\nAjustement du mod√®le Random Effects (RE) avec log(EARNIMP4)...\n")
re_modelLIN <- plm(formula, data = pdata, model = "random",effect="time")
cat("R√©sum√© du mod√®le Random Effects :\n")
print(summary(re_modelLIN))

vif2<-vif(re_modelLIN)
print(vif2)
cat("\nAjustement du mod√®le Random Effects (RE) avec log(EARNIMP4)...\n")
re_indiv <- plm(formula, data = pdata, model = "random",effect="indiv")
cat("R√©sum√© du mod√®le Random Effects :\n")
print(summary(re_indiv))


cat("\nAjustement du mod√®le Random Effects (RE) avec log(EARNIMP4)...\n")
re_randomtwo <- plm(formula, data = pdata, model = "random",effect="twoways")
cat("R√©sum√© du mod√®le Random Effects :\n")
print(summary(re_randomtwo ))


# Between Effects (BE)
cat("\nAjustement du mod√®le Between Effects (BE) avec log(EARNIMP4)...\n")
be_modelTIME <- plm(formula, data = pdata, model = "between",effect="time")
cat("R√©sum√© du mod√®le Between Effects :\n")
print(summary(be_modelTIME))


bptest(be_modelTIME)
bptest(fe_modelLIN)
# Between Effects (BE)
cat("\nAjustement du mod√®le Between Effects (BE) avec log(EARNIMP4)...\n")
be_modelINDIV <- plm(formula, data = pdata, model = "between",effect="indiv")
cat("R√©sum√© du mod√®le Between Effects :\n")
print(summary(be_modelINDIV))

# Pour le mod√®le avec effet temporel
coeftest_be_modelTIME_robust <- coeftest(be_modelTIME, vcov = vcovHC(be_modelTIME, method = "arellano", type = "HC0"))
print(coeftest_be_modelTIME_robust)

# Pour le mod√®le avec effet individuel
coeftest_be_modelINDIV_robust <- coeftest(be_modelINDIV, vcov = vcovHC(be_modelINDIV, method = "arellano", type = "HC0"))
print(coeftest_be_modelINDIV_robust)



##tEST  de HAUSMAN : 
phtest(re_m)

##test
library(lmtest)
pFtest(fe_modelLIN, test="Chisq")


phtest(fe_modelLIN, re_modelLIN)

library(car)
vif1<-vif(be_modelLIN)
print(vif1)

library(lmtest)
coeftest(be_modelLIN, vcov = vcovHC(be_modelLIN, type = "HC0", cluster = "group"))

###Faire le test de Mundlak
# Charger les packages n√©cessaires
library(plm)


# Cr√©er les moyennes individuelles des variables explicatives
df_panel$VEGENO_mean <- ave(df_panel$VEGENO, df_panel$id, FUN=mean)
df_panel$ORANGYR_mean <- ave(df_panel$ORANGYR, df_panel$id, FUN=mean)
df_panel$FRUTNO_mean <- ave(df_panel$FRUTNO, df_panel$id, FUN=mean)
df_panel$BREAKFAST_mean <- ave(df_panel$BREAKFAST, df_panel$id, FUN=mean)
df_panel$HRSLEEP_mean <- ave(df_panel$HRSLEEP, df_panel$id, FUN=mean)
df_panel$VIG10DMIN_mean <- ave(df_panel$VIG10DMIN, df_panel$id, FUN=mean)
df_panel$AGE_mean <- ave(df_panel$AGE, df_panel$id, FUN=mean)
df_panel$SEX_mean <- ave(df_panel$SEX, df_panel$id, FUN=mean)

# Appliquer la r√©gression Mundlak avec le mod√®le √† effets al√©atoires
formula_mundlak <- log(EARNIMP4) ~ VEGENO + ORANGYR + FRUTNO + BREAKFAST + HRSLEEP + 
  VIG10DMIN + AGE + I(AGE^2) + SEX +
  EDUC_13 + EDUC_14 + EDUC_3eme + EDUC_4eme + EDUC_5eme  + 
  EDUC_Bac2technique + EDUC_Bac2univ + EDUC_Bachelor + EDUC_Bacrate + 
  EDUC_CE1 + EDUC_CE2 + EDUC_CM1 + EDUC_CM2 + EDUC_CP + EDUC_Doctorat + 
  EDUC_Doctoratpro + EDUC_EcolePro + EDUC_Lyceeadulte + EDUC_Master + 
  EDUC_Maternelle + EDUC_Premiere + EDUC_Seconde +
  VEGENO_mean + ORANGYR_mean + FRUTNO_mean + BREAKFAST_mean + 
  HRSLEEP_mean + VIG10DMIN_mean + AGE_mean + SEX_mean

model_mundlak <- plm(formula_mundlak, data = df_panel, model = "random")

# R√©sum√© des r√©sultats
summary(model_mundlak)




cat("\nAjustement du mod√®le Between Effects (BE) avec log(EARNIMP4)...\n")
be_modelLIN <- plm(formula, data = pdata, model = "between",effect="indiv")
cat("R√©sum√© du mod√®le Between Effects :\n")
print(summary(be_modelLIN))


cat("\nAjustement du mod√®le Between Effects (BE) avec log(EARNIMP4)...\n")
be_modelLIN <- plm(formula, data = pdata, model = "between",effect="twoways")
cat("R√©sum√© du mod√®le Between Effects :\n")
print(summary(be_modelLIN))





library("lmtest")
bptest(be_modelLIN)

#multicolin√©arit√©. 
library(car)
vif(be_modelLIN)


library(nlme)
###Faire un gls pour r√©soudre le probl√®me d'h√©t√©rosc√©dasticit√©

# Charger les packages n√©cessaires
library(nlme)
library(dplyr)

# V√©rifier si SERIAL est bien d√©fini comme un facteur
pdata <- pdata %>%
  mutate(SERIAL = as.factor(SERIAL))  # Si SERIAL est un identifiant de groupe

# Ajustement du mod√®le GLS
gls_model <- gls(
  EARNIMP4 ~ BREAKFAST + HRSLEEP + EDUC + MOD10DMIN + VEGENO + SEX + I(AGE^2) + AGE, 
  data = pdata,
  correlation = corAR1(form = ~1 | SERIAL),  # Structure de corr√©lation temporelle
  weights = varIdent(form = ~1 | SERIAL)     # H√©t√©rosc√©dasticit√© par groupe SERIAL
)

# R√©sum√© du mod√®le
summary(gls_model)







#on la remplac√© par MOD10DMIN


library(sandwich)
library(lmtest)
# Erreurs robustes de type White
coeftest(be_modelLIN, vcov = vcovHC(be_modelLIN, type = "HC0"))


library(nlme)

# Ajustement du mod√®le GLS
gls_model <- gls(
  formula = formula, 
  data = pdata, 
  correlation = corAR1(form = ~year),  # Corr√©lation AR(1) sur les ann√©es
  weights = varIdent(form = ~1 | SERIAL) # Variance diff√©rente par entreprise
)

# R√©sum√© du mod√®le
summary(gls_model)



####Tests 


###Derniere regression. remodifier la formula qqpart svp

# Formule de r√©gression (ajout de SEXE et AGE)
formula <- EARNIMP4 ~  FRUTNO + VEGENO + BREAKFAST  + HRSLEEP + VIG10DMIN + EDUC + SEX + AGE

# V√©rification des donn√©es panel
if (!"pdata.frame" %in% class(pdata)) {
  pdata <- pdata.frame(pdata, index = c("id", "time"))  # Remplacez "id" et "time" par vos colonnes d'index
}

library("plm")

#OLS 
model <- lm(formula, data = pdata)
summary(model)
BIC(model)

# Pooled OLS
cat("Ajustement du mod√®le Pooled OLS avec log(EARNIMP4)...\n")
pooled_modelLIN <- plm(formula, data = pdata, model = "pooling")
cat("R√©sum√© du mod√®le Pooled OLS :\n")
print(summary(pooled_modelLIN))

# Fixed Effects (FE)
cat("\nAjustement du mod√®le Fixed Effects (FE) avec log(EARNIMP4)...\n")
fe_indiv_LOG <- plm(formula, data = pdata, model = "within",effect="indiv")
cat("R√©sum√© du mod√®le Fixed Effects :\n")
print(summary(fe_indiv_LOG))

library(car)
fixedeffect<-vif(fe_indiv_LOG)


#Effet fixe temporel 
fe_timeLOG <- plm(formula, data = pdata, model = "between", effect = "time")
summary(fe_timeLOG)


#Effet fixe twoways 
fe_twoLOG <- plm(formula, data = pdata, model = "within", effect = "twoways")
summary(fe_timeLOG)

fgls1<-fgls()

# Random Effects (RE)
cat("\nAjustement du mod√®le Random Effects (RE) avec log(EARNIMP4)...\n")
re_modelLIN <- plm(formula, data = pdata, model = "random")
cat("R√©sum√© du mod√®le Random Effects :\n")
print(summary(re_modelLIN))
library(stargazer)
stargazer (fe_modelLIN, re_modelLIN)

# Between effects (BE) twoways impossible !
anova(fe_indiv_LOG,be_modelLIN)

#Effet between individuel

library(plm)

cat("\nAjustement du mod√®le Between Effects (BE) sur les individus avec log(EARNIMP4)...\n")
be_modelLIN <- plm(formula, data = pdata, model = "between", effect="indiv")

cat("R√©sum√© du mod√®le Between Effects individuel :\n")
print(summary(be_modelLIN))

#Modele Between temporel 

# D√©finition de la formule (m√™me que pr√©c√©demment)
formula <- EARNIMP4 ~ ORANGYR  + BREAKFAST + SNACKS + HRSLEEP +
  VIG10DMIN + EDUC + SEX + AGE +I(AGE^2)

cat("\nAjustement du mod√®le Between Effects (BE) sur les individus avec log(EARNIMP4)...\n")
be_modelLIN <- plm(formula, data = pdata, model = "between", effect = "time")
#Model=type de mod√®le en BETWEEN EFFECT
#Ici R2 de 0,90.  
#Mais significativit√©. 
cat("R√©sum√© du mod√®le Between Effects individuel :\n")
print(summary(be_modelLIN))


##GLS: 
library(nlme)
library(plm)

# Mod√®le GLS Between avec effets fixes temporels
be_gls <- gls(
  formula,  # Effet fixe temporel
  data = pdata,
  effect=time,
  method = "REML"
)

# Affichage des r√©sultats
summary(be_gls)


library(plm)
library(nlme)

# üìå 1. Estimer le mod√®le Between classique
be_model <- plm(log(EARNIMP4) ~ EDUC_13 + EDUC_14 + EDUC_3eme + EDUC_4eme + EDUC_5eme + EDUC_6eme +
                  EDUC_Bac2technique + EDUC_Bac2univ + EDUC_Bachelor + EDUC_Bacrate + 
                  EDUC_CE1 + EDUC_CE2 + EDUC_CM1 + EDUC_CM2 + EDUC_CP + 
                  EDUC_Doctorat + EDUC_Doctoratpro + EDUC_EcolePro + EDUC_Lyceeadulte + 
                  EDUC_Master + EDUC_Maternelle + EDUC_Premiere + EDUC_Seconde + SEX_2 + 
                  experience + I(experience^2),
                data = pdata, model = "between", effect = "individual")

# üìå 2. V√©rifier la structure de l'h√©t√©rosc√©dasticit√©
library(lmtest)
bptest(be_modelLIN)  # Test de Breusch-Pagan pour l'h√©t√©rosc√©dasticit√©
library(nlme)
# üìå 3. Appliquer FGLS avec correction de variance
fgls_be <- gls(formula,
               data = pdata, weights = varIdent(form = ~ 1 | SERIAL), method = "ML")

summary(fgls_be)


###Le Between est le mod√®le le plus performant, avec un R2 ajust√© le plus √©lev√©.
#Afin d'√©viter de tomber dans le datamining, on va v√©rifier avec le test d'Hausman 
library(sandwich)
library(lmtest)
coeftest(be_modelLIN, vcov=vcovHC(be_modelLIN),type="HC0")

###Test d'h√©t√©rosc√©dasticit√©
bptest(be_modelLIN)

#Donc H1 est v√©rifi√©, il y a bien h√©t√©rosc√©dasticit√© dans mon mod√®le. 
#Ainsi les tests des significativit√© sont incoh√©rentes. 
model_1_coef <- lmtest::coeftest(be_modelLIN, vcov = sandwich::vcovHC) 

##Quels premiers Tests  de modele 
library(car)
vif<-vif(be_modelLIN)
print(vif)
#On remarque que la variable breakfast est fortement colin√©aire √† la variable snack.
#on va donc d√©cider 'enlever la variable snack et voir la diff√©rence aussi avec breakfast. 








####bonne r√©gression 

#1:effet temporel 
formula <- EARNIMP4 ~ ORANGYR + FRUITMO + BREAKFAST  + HRSLEEP +
  VIG10DMIN + EDUC + SEX + AGE +I(AGE^2)

cat("\nAjustement du mod√®le Between Effects (BE) sur les individus avec log(EARNIMP4)...\n")
be_modelLIN <- plm(formula, data = pdata, model = "between", effect = "time")
#Model=type de mod√®le en BETWEEN EFFECT
summary(be_modelLIN)

#2 : :effet individuel; 
formula <- EARNIMP4 ~ ORANGYR + FRUITMO + BREAKFAST  + HRSLEEP +
  VIG10DMIN + EDUC + SEX + AGE +I(AGE^2)

cat("\nAjustement du mod√®le Between Effects (BE) sur les individus avec log(EARNIMP4)...\n")
be_indivLIN <- plm(formula, data = pdata, model = "between", effect = "indiv")
#Model=type de mod√®le en BETWEEN EFFECT
summary(be_indivLIN)

vif2<-(be_modelLIN)
print(vif2)

#Pour rappelle, ici on a 

##
model_1_coef <- lmtest::coeftest(be_modelLIN, vcov = sandwich::vcovHC) 


coeftest(be_modelLIN, vcov=vcovHC(be_modelLIN, type="HC1", cluster="group"))
vcov_robuste <- vcovHC(be_modelLIN, type = "HC1")

###Tests li√©s notamment au panel de Breuschpagan pour l'effet temporel : 
x¬≤

##TEST EFFET FIXE TEMPOREL VS EFFET FIXE INDIVIDUEL : 

pFtest(be_modelLIN, be_indivLIN)
#Test : pour le temps fix√©, 
#H0 est rejet√© , donc on aura bien l'effet temporel ! 

##TEST  : 
plmtest(pooled_model, type=c("bp"))

##Correction
install.packages("pl")
library(plm)

library(plm)
library(lmtest)
pcse_model <- psce(formula, data = pdata, 
                   groupN = pdata$SERIAL, groupT = pdata$YEAR)
summary(pcse_model)

#Test d'autocorr√©lation
pwartest(be_modelLIN)
dwtest(be_modelLIN)

#On s'apercoit que la s√©rie est non stationnaire, on va donc tenter de faire une r√©gression de premiere diff√©rence. 
library(tseries)
adf.test(pdata$EARNIMP4, k=2)
first_diff_model <- plm(formula, 
                        data = pdata, model = "fd")
summary(first_diff_model)

#GMM :
install.packages("plm")
install.packages("pgmm")

library(plm)
library(pgmm)

# Estimation GMM dynamique
gmm_model <- pgmm(EARNIMP4 ~ lag(EARNIMP4, 1) + ORANGYR + FRUITMO + BREAKFAST + 
                    HRSLEEP + VIG10DMIN + EDUC + SEX + AGE + I(AGE^2) |
                    lag(EARNIMP4, 2:5),  # Instruments: retards 2 √† 5
                  data = pdata, effect = "individual", model = "twosteps")

# R√©sum√© du mod√®le GMM
summary(gmm_model)

#Multinomial
install.packages("mlogit")   # Pour le mod√®le logit multinomial
install.packages("nnet")     # R√©gression multinomiale

library(mlogit)
library(nnet)
# Conversion des donn√©es au format mlogit
data_mlogit <- mlogit.data(pdata, choice = "EARNIMP4", shape = "long", alt.levels = unique(data$EARNIMP4))

# Estimation d'un mod√®le Multinomial Logit avec effets fixes
mlogit_model <- mlogit(EARNIMP4 ~ ORANGYR + FRUITMO + BREAKFAST + HRSLEEP + 
                         VIG10DMIN + EDUC + SEX + AGE + I(AGE^2) + EARNIMP4_lag | 0, 
                       data = data_mlogit, reflevel = "1")

summary(mlogit_model)





#Test d'autocorr√©altion
install.packages("geepack")
library(lme4)
library(lme4)
l1 <- lmer(formula, data = pdata) 
lmer.display(l1, ci.ranef = T)



###Test de Pesaran

pcdtest(be_modelLIN, test = c("cd"))



vif(fe_modelLIN)
# Estimateur Within total
b_within <- plm(formula , data = pdata, model="within", effect="twoways")
summary(b_within)
coeftest(b_within)

##Within individuel 
b_within_i <- plm(formula, data = pGrunf4, model="within", effect="indiv")
summary(b_within_i)

####A noter : la dummysation pour le sexe. 
cat("\nAjustement du mod√®le Between Effects (BE) sur les individus avec log(EARNIMP4)...\n")
be_modelLIN <- plm(formula, data = pdata, model = "between", effect = "time")
#Model=type de mod√®le en BETWEEN EFFECT
#Ici R2 de 0,90.  
#Mais significativit√©. 
cat("R√©sum√© du mod√®le Between Effects individuel :\n")
print(summary(be_modelLIN))

###EFFETS NON LINEAIRES : 

# D√©finition de la formule (m√™me que pr√©c√©demment)
formula <- EARNIMP4 ~ ORANGYR + FRUITMO + BREAKFAST + SNACKS + HRSLEEP +
  VIG10DMIN + EDUC + SEX + AGE +I(AGE^2)

cat("\nAjustement du mod√®le Between Effects (BE) sur les individus avec log(EARNIMP4)...\n")
be_modelLIN <- plm(formula, data = pdata, model = "between", effect = "time")
#Model=type de mod√®le en BETWEEN EFFECT
#Ici R2 de 0,90.  
#Mais significativit√©. 
cat("R√©sum√© du mod√®le Between Effects individuel :\n")
print(summary(be_modelLIN))

formula <- EARNIMP4 ~ ORANGYR + FRUITMO + BREAKFAST + SNACKS + HRSLEEP+I(HRSLEEP^2) +
  VIG10DMIN + EDUC + SEX + AGE +I(AGE^2)
cat("\nAjustement du mod√®le Between Effects (BE) sur les individus avec log(EARNIMP4)...\n")
be_modelLINPOLY <- plm(formula, data = pdata, model = "between", effect = "time")
#Model=type de mod√®le en BETWEEN EFFECT
#Ici R2 de 0,90.  
#Mais significativit√©. 
cat("R√©sum√© du mod√®le Between Effects individuel :\n")
print(summary(be_modelLINPOLY))

####Exhaustive search sur toute la base de donn√©es 

# Installer leaps si n√©cessaire
library(leaps)
# Recherche exhaustive sur toutes les variables explicatives
model <- regsubsets(EARNIMP4 ~ ., data = data, nbest = 4, method = "exhaustive")

# R√©sum√© des meilleurs mod√®les
summary_model <- summary(model)

# Affichage des meilleurs mod√®les
print(summary_model)

cat("\nAjustement du mod√®le Between Effects (BE) sur les individus avec log(EARNIMP4)...\n")
be_modelLINPOLY <- plm(formula, data = pdata, model = "between", effect = "indiv")
#Model=type de mod√®le en BETWEEN EFFECT
#Ici R2 de 0,90.  

####Modeles avec variable dependante Y limit√©e: 

#1:FGLS √† tester pour corriger l'h√©t√©rosc√©dasticit√©. 
# Charger le package plm (si ce n'est pas d√©j√† fait)
if(!require(plm)) install.packages("plm")
library(plm)

# D√©finition de la formule (m√™me que pr√©c√©demment)
formula <- EARNIMP4 ~ ORANGYR + FRUITMO + BREAKFAST  + HRSLEEP +
  VIG10DMIN + EDUC + SEX + AGE







###FGLS: 

fe_twoLOG <- plm(formula, data = pdata, model = "within", effect = "twoways")
summary(fe_twoLOG)

# Estimation du mod√®le FGLS entre (using pggls)
fgls_model <- pggls(formula, data = pdata, model = "between",effect="time")

# Afficher le r√©sum√© du mod√®le FGLS
summary(fgls_model)

library(lme4)

# Mod√®le Between avec un effet al√©atoire
model_lme_between <- lmer( formula + 1 | SERIAL),
                          data = pdata)

# R√©sum√© du mod√®le
summary(model_lme_between)
,               


library(plm)
library(car)
library(lmtest)
library(sandwich)
library(nlme)

best_model_selector <- function(data, formula, index) {
  # Liste des mod√®les test√©s
  models <- list()
  vif_values <- list()
  r2_values <- list()
  valid_models <- list()
  
  # 1. Mod√®le OLS
  model_ols <- lm(formula, data = data)
  models$OLS <- model_ols
  vif_values$OLS <- max(vif(model_ols), na.rm = TRUE)
  r2_values$OLS <- summary(model_ols)$adj.r.squared
  
  # 2. Mod√®le Between
  model_between <- plm(formula, data = data, index = index, model = "between")
  models$Between <- model_between
  vif_values$Between <- max(vif(lm(formula, data = data)), na.rm = TRUE)  # VIF estim√© sur OLS
  r2_values$Between <- summary(model_between)$r.squared
  
  # 3. Mod√®le Within (Effets Fixes - Individuel)
  model_within_indiv <- plm(formula, data = data, index = index, model = "within", effect = "individual")
  models$Within_Indiv <- model_within_indiv
  vif_values$Within_Indiv <- max(vif(lm(formula, data = data)), na.rm = TRUE)
  r2_values$Within_Indiv <- summary(model_within_indiv)$r.squared
  
  # 4. Mod√®le Within (Effets Fixes - Temporel)
  model_within_time <- plm(formula, data = data, index = index, model = "within", effect = "time")
  models$Within_Time <- model_within_time
  vif_values$Within_Time <- max(vif(lm(formula, data = data)), na.rm = TRUE)
  r2_values$Within_Time <- summary(model_within_time)$r.squared
  
  # 5. Mod√®le Within (Effets Fixes - Deux Voies)
  model_within_twoways <- plm(formula, data = data, index = index, model = "within", effect = "twoways")
  models$Within_Twoways <- model_within_twoways
  vif_values$Within_Twoways <- max(vif(lm(formula, data = data)), na.rm = TRUE)
  r2_values$Within_Twoways <- summary(model_within_twoways)$r.squared
  
  # 6. Mod√®le GLS
  model_gls <- gls(formula, data = data, correlation = corCompSymm(form = ~ 1 | data[[index[1]]]), method = "REML")
  models$GLS <- model_gls
  vif_values$GLS <- max(vif(lm(formula, data = data)), na.rm = TRUE)
  r2_values$GLS <- summary(model_gls)$r.squared
  
  # V√©rification des mod√®les valides
  for (m in names(models)) {
    model <- models[[m]]
    if (r2_values[[m]] > 0.5 && vif_values[[m]] < 10) {
      coefs <- summary(model)$coefficients
      p_vals <- coefs[, 4]  # p-values
      if (sum(p_vals > 0.05, na.rm = TRUE) <= 3) {
        valid_models[[m]] <- model
      }
    }
  }
  
  # 7. S√©lection du mod√®le final
  if (length(valid_models) > 0) {
    best_model <- valid_models[[which.max(sapply(valid_models, function(m) summary(m)$adj.r.squared))]]
  } else {
    # Choisir le mod√®le avec le R¬≤ ajust√© le plus √©lev√© et VIF < 10
    best_model_name <- names(which.max(r2_values))
    best_model <- models[[best_model_name]]
  }
  
  return(best_model)
}



best_model <- best_model_selector(data, formula, index)
summary(best_model)


#2:modele logitordonn√© 
library(plm)
install.packages("ordinal")
library(ordinal)
install.packages("oglmx")
library(oglmx)
install.packages("lmtest")
library(lmtest)


formula <- as.formula(paste("factor(", all.vars(formula)[1], ") ~", paste(all.vars(formula)[-1], collapse=" + ")))

model_ordinal_fe <- clm(EARNIMP4 ~ ORANGYR + FRUITMO + BREAKFAST  + HRSLEEP +
                          VIG10DMIN + EDUC + SEX + AGE, data=pdata)
summary(model_ordinal_fe)


###LOGIT ORDERED 
install.packages(c("mlogit", "dplyr", "data.table", "Rcrologit"))

library(mlogit)      # Mod√©lisation des choix discrets
library(dplyr)       # Manipulation des donn√©es
library(data.table)  # Gestion efficace des grands datasets
library(Rcrologit)   # Mod√©lisation du conditional rank-ordered logit

# Transformation et pr√©paration des donn√©es pour le mod√®le logit conditionnel
dataprep <- dataPrep(
  data,
  idVar = "SERIAL",  # Identifiant unique de chaque individu
  rankVar = "rank",  # Variable repr√©sentant l‚Äôordre des pr√©f√©rences
  altVar = "alternative",  # Variables alternatives consid√©r√©es dans le mod√®le
  covsInt.fix = list("Gender"),  # Covariables fixes interagissant avec les alternatives
  covs.fix = list("log_Wage"),  # Variables explicatives fixes
  FE = c("Firm_ID")  # Effets fixes au niveau de l‚Äôentreprise
)
# V√©rifier et transformer EARNIMP4 en facteur ordonn√©
data$EARNIMP4 <- as.ordered(data$EARNIMP4)

# V√©rifier et transformer persons en facteur si n√©cessaire
data$SERIAL <- as.factor(datapersons)

# Mod√®le de r√©gression logistique ordonn√©e
polrModel <- polr(formula, 
                  data = training, Hess = TRUE)

# R√©sum√© des r√©sultats
summary(polrModel)



summary(data)

###ORDONNE DE PANEL : 
install.packages("VGAM")
library(VGAM)
# Mod√®le Probit Ordonn√©
model <- vglm(formula, family=propodds(probit), data=pdata)

# R√©sum√© du mod√®le
summary(model)

###On le justifie parce que la variable Y est ordonn√©e de 1 √† 20 ici ! 

###3 Tobit de panel
library(pglm)

data('pdata', package = 'pglm')
model_ordonn√© <- pglm(formula,  # Variables explicatives
                      data = pdata, 
                      family = ordinal("probit"),
                      R=5,# Mod√®le Tobit (censur√©),
                      print.level  =  3 ,
                      method = "bfgs",
                      model = "within" )  # Algorithme d'optimisation
summary(model_ordonn√©)
fixed <- c(TRUE, FALSE, TRUE,TRUE,TRUE,TRUE,TRUE,TRUE) 


n <- length(coef(formula))  # Nombre de variables explicatives dans le mod√®le
start_values <- rep(0, n)   # Cr√©e un vecteur de z√©ros avec n √©l√©ments (un pour chaque param√®tre)
model_ordonn√© <- pglm(formula, 
                      data = pdata, 
                      family = ordinal("probit"),
                      R = 5,
                      print.level = 3,
                      method = "bfgs",
                      model = "within",
                      start = start_values,
                      fixed)

# Cr√©er des valeurs initiales (par exemple, des z√©ros)
start_values <- rep(0, length(coef(formula)))  # Ou utilisez une r√©gression ordinaire pour une estimation plus pr√©cise

library(pglm)
library(plm)  # Pour g√©rer les donn√©es en panel

# V√©rifier la structure des donn√©es
str(pdata)
head(pdata)

pdata <- pdata.frame(pdata, index = "serial")
model_ordonn√© <- pglm(formula, 
                      data = pdata, 
                      family = ordinal("probit"),
                      R = 5,
                      print.level = 3,
                      method = "bfgs",
                      model = "within",
                      start = rep(0, length(coef(lm(formula, data = pdata)))))

model_ordonn√© <- pglm(formula, 
                      data = pdata, 
                      family = ordinal("probit"),
                      R = 5,
                      print.level = 3,
                      method = "nr",
                      model = "between")


# Rank-ordered logit
dataprep <- dataPrep(data, idVar = "SERIAL", rankVar = "rank",
                     altVar = "alternative",
                     covsInt.fix = list("AGE,SEX"),
                     covs.fix = list("log_Wage"), FE = c("Firm_ID"))

rologitEst <- rcrologit(dataprep)





# Charger le package brms (et ses d√©pendances)
install.packages("brms")
library(brms)

# V√©rifiez la structure de vos donn√©es (optionnel)
str(pdata)

# Estimation du mod√®le Tobit en panel avec brms
# Ici, la syntaxe "y | cens(cens)" permet de pr√©ciser la variable indiquant la censure.
fit_tobit <- brm(formula = bf(EARNIMP4~ ORANGYR + FRUITMO + BREAKFAST + SNACKS + HRSLEEP + VIG10DMIN + EDUC + SEX + AGE,
                              data = pdata,
                              family = gaussian(),   # le mod√®le Tobit classique repose sur une loi normale pour le latent
                              chains = 2,            # ajustez le nombre de cha√Ænes selon vos besoins
                              iter = 2000,           # nombre d'it√©rations par cha√Æne
                              seed = 123             # pour la reproductibilit√©
)

# Affichage du r√©sum√© du mod√®le
summary(fit_tobit)

# Charger le package brms
library(brms)

# Assurez-vous que la variable de r√©ponse est un facteur
pdata$EARNIMP4 <- as.factor(pdata$earnimp4)

# Exemple avec une variable explicative "x" (remplacez "x" par vos pr√©dicteurs si besoin)
# Estimation du mod√®le multinomial
fit_multinom <- brm(
  formula = EARNIMP4 ~ ORANGYR + FRUITMO + BREAKFAST + SNACKS + HRSLEEP +
    VIG10DMIN + EDUC + SEX + AGE,
  data = pdata,
  family = categorical(),  # Indique un mod√®le multinomial
  chains = 2,              # Pour un test rapide ; augmentez (ex. √† 4) pour l'analyse finale
  iter = 2000,             # Nombre d'it√©rations par cha√Æne
  seed = 123
)

# Affichage du r√©sum√© du mod√®le
summary(fit_multinom)




#####Nouvelles id√©es am√©liorer le remplacement de d√©part par la m√©diane. 

library(VIM)  
newdata <- data[EARNIMP4,ORANGYR,FRUITMO,BREAKFAST,SNACKS,HRSLEEP,VIG10DMIN,EDUC,SEX,AGE]
dataimputed <- kNN(newdata, k = 3)  # Ajuster k pour la vitesse







###TESTS DE PERFORMANCE : 

# Existence  :F-test entre pooled et within 
pFtest(fe_indiv_LOG,pooled_model)
#Il appara√Æt √©vident que l'effet fixe est pr√©f√©r√© 
# Comparaison des modeles avec R2 et Fischer les plues eleves  : 
pFtest(be_modelLIN,fe_indiv_LOG)

#Test notamment li√© √† l'effet temporel ? 
plmtest(be_modelLIN, effect = "time", type = "bp")

# F-test pour les effets temporels
pFtest(fe_timeLOG, pooled_model)





install.packages("effectsize")
library(effectsize)

# Convertir automatiquement en coefficients non standardis√©s
unstandardized_coeffs <- unstandardize_parameters(be_modelLIN,data=pdata)

print(unstandardized_coeffs)

# Test de Hausman entre effet fixe et al√©atoire. 
cat("\nTest de Hausman entre le mod√®le √† effets fixes (FE) et √† effets between")
hausman_test <- phtest(fe_modelLIN, re_modelLIN)

#Aleatoire vsOLS : Afficher les r√©sultats du test de Hausman
print(hausman_test)

###Le test de Hausman, avec une p-value inf√©rieur √† 0,05.
###On rejette les effets al√©atoires, et on pr√©f√®re le mod√®le √† effet fixe within
###Ainsi, m√™me si le R2 d'al√©atoire est plus √©lev√©, Hausman souligne un impact causal plus √©lev√© du Within
#En soit le R2, ou R2 ajust√© qui sont proches ici ; ne sont pas forc√©ment la mesure la plus importante . 


###Tests pour l'al√©atoire
library(plm)
library(lmtest)

cat("\nTest de Breusch-Pagan pour choisir entre Pooled OLS et Random Effects...\n")
bp_test <- plmtest(pooled_modelLIN, type = "bp")
print(bp_test)

#La p-value est faible, le random effect est pr√©f√©rable au mod√®le pool√© 

####Test de Mundlack 
# Test de Breusch-Pagan pour les effets individuels
plmtest(pooling, type = "bp")

# Comparaison des mod√®les avec stargazer (facultatif)
if ("stargazer" %in% installed.packages()) {
  library(stargazer)
  cat("\nComparaison des mod√®les :\n")
  stargazer(pooled_modelLIN, fe_modelLIN, re_modelLIN, be_modelLIN, 
            type = "text", title = "Comparaison des mod√®les d'estimation panel")
}

####Test d'autocorr√©lation pour le Within. 
install.pacakges("lmtest")
library(lmtest)
bgtest(pooled_modelLIN)  # Test de Breusch-Godfrey sur le mod√®le Pooled OLS
###On peut conclure qu'il y a autocorr√©lation pour le Within. 
bgtest(fe_modelLIN) 
#Il y a un effet fixe dans Lmtest !

#Test de Mundlak 
cat("\nTest de Mundlak pour v√©rifier la corr√©lation entre effets individuels et variables explicatives...\n")
mundlak_test <- plm(formula, data = pdata, model = "random")
mundlak_test <- update(mundlak_test, . ~ . + I(fitted(re_modelLIN)))
print(summary(mundlak_test))

###Reprendre les exercices : qui sera publi√© !*




###Interpr√©ter le modele au R2 de 0,90 ajust√©. 
# Charger les packages n√©cessaires
library(plm)
library(lmtest)
library(sandwich)
test_results <- coeftest(be_modelLIN, vcov = vcovBK(be_modelLIN, type = "HC3"))

# Affichage des r√©sultats du test
print(test_results)

library(data.table)
#Calculer les √©carts types. 
ecarts_types <- data[, lapply(.SD, sd, na.rm = TRUE)]
print(ecarts_types)




#Interpr√©tations des coefficients du meilelure modele : √† savoir le between idnividuel

# Charger les packages n√©cessaires
library(plm)
library(lmtest)

summary(be_modelLIN)
# Test des coefficients avec des erreurs standards robustes
# Ici, nous utilisons la fonction vcovHC pour obtenir des erreurs robustes
test_results <- coeftest(be_modelLIN, type="between", vcov = vcovHC(be_modelLIN, method = "arellano", type = "HC0"))

# Affichage des r√©sultats du test
print(test_results)

#M√©thode 2 : HAC : 
vcov_hac <- vcovNW(be_modelLIN, lag = 2, prewhite = TRUE)
new<-coeftest(be_modelLIN, vcov. = Newestwey)
print(new)


vcov_robuste <- vcovHC(modele, type = "HC1")

vcov_robuste <- vcovHC(be_modelLIN, type = "HC1")



#Test d'autocorr√©lation
library(plm)
library(lmtest)

pdwtest(be_modelLIN)
























####Test de stationnarit√©
install.packages("tseries")
library(tseries)

cat("\nTest de stationnarit√© Levin-Lin-Chu sur la variable d√©pendante...\n")
llc_test <- levinlin.test(pdata$EARNIMP4)
print(llc_test)




####


####Partie corr√©lation : 

# Chemin vers le fichier de donn√©es
file_path <- "C:/Users/grego/OneDrive/Documents/sampled_data1.csv"
correlation_output_path <- "C:/Users/grego/OneDrive/Documents/correlation_matrix.txt"

# Charger les biblioth√®ques n√©cessaires
library(readr)

# Fonction pour calculer et exporter la matrice de corr√©lation
compute_and_export_correlation_matrix <- function(file_path, output_path) {
  # Charger les donn√©es
  cat("Chargement des donn√©es...\n")
  data <- read_csv(file_path)
  
  # S√©lectionner uniquement les colonnes num√©riques
  cat("S√©lection des colonnes num√©riques...\n")
  numeric_data <- data[, sapply(data, is.numeric)]
  
  # V√©rifier qu'il y a des colonnes num√©riques
  if (ncol(numeric_data) == 0) {
    stop("Aucune colonne num√©rique trouv√©e dans la base de donn√©es.")
  }
  
  # Calculer la matrice de corr√©lation
  cat("Calcul de la matrice de corr√©lation...\n")
  correlation_matrix <- cor(numeric_data, use = "pairwise.complete.obs")
  
  # Exporter la matrice dans un fichier texte
  cat("Exportation de la matrice de corr√©lation...\n")
  write.table(round(correlation_matrix, 2), file = output_path, sep = "\t", quote = FALSE)
  cat(sprintf("Matrice de corr√©lation export√©e avec succ√®s dans '%s'.\n", output_path))
  
  # Retourner la matrice de corr√©lation pour affichage √©ventuel
  return(round(correlation_matrix, 2))
}

# Calculer et exporter la matrice de corr√©lation
correlation_matrix <- compute_and_export_correlation_matrix(file_path, correlation_output_path)

# Afficher la matrice dans la console
cat("Matrice de corr√©lation :\n")
print(correlation_matrix)

###Corr√©lations entre le revenu et le reste des variables
# Installer et charger les packages n√©cessaires (si ce n'est d√©j√† fait)
if (!require(ggplot2)) install.packages("ggplot2")
if (!require(reshape2)) install.packages("reshape2")
library(ggplot2)
library(reshape2)

# D√©finir les chemins d'acc√®s aux fichiers
# Remplacez par le chemin de votre fichier de donn√©es
correlation_output_path <- "C:/Users/grego/OneDrive/Documents/matrice_corr.csv" # Remplacez par le chemin souhait√© pour l'export


# Calculer la matrice de corr√©lation en utilisant uniquement les observations compl√®tes
correlation_matrix <- cor(data, use = "complete.obs")

# Exporter la matrice de corr√©lation dans un fichier CSV
write.csv(correlation_matrix, correlation_output_path, row.names = TRUE)

# Afficher la matrice compl√®te dans la console
cat("Matrice de corr√©lation :\n")
print(correlation_matrix)

# Extraction et affichage des corr√©lations entre 'revenu' et les autres variables
if ("revenu" %in% colnames(data)) {
  revenu_correlations <- correlation_matrix[, "revenu"]
  cat("\nCorr√©lation entre 'revenu' et le reste des variables :\n")
  print(revenu_correlations)
} else {
  cat("\nLa colonne 'revenu' n'existe pas dans les donn√©es.\n")
}



###Corr√©lation li√©es uniquement aux variables du syst√®me afin de v√©rifier multicolin√©arit√© parfaite. 
data <- read_csv("C:/Users/grego/OneDrive/Documents/sampled_data1.csv") %>% select(all.vars(EARNINGS ~ VEGMO + ORANGYR + FRUITMO + BREAKFAST + SNACKS + HRSLEEP + VIG10DMIN + EDUC))
print(round(cor(data, use = "pairwise.complete.obs"), 2))
#On peut observer au dela de probleme de valeurs manquantes, une relation entre le snacks et breakfast trop forte
#Cela para√Æt logique, √©tant donn√© que des personnes aiment bien le sal√© au petit-d√©jeuner, notamment aux USA

#Le nombre d'heures de sommeil est corr√©l√© positivement √† breakfast. 
#OrangeYR appara√Æt √™tre trop peu reli√©e pour √™tre consid√©r√©e comme une variable omise. 
#On peut remarque forte corr√©lation entre la variable FRUIT ET LEGUMES 
#Cela pousse fortement √† faire une ACP afin de r√©sumer au mieux

####GMM Arellano-bond
install.packages("plm")
install.packages("AER")   # Pour tester l'autocorr√©lation
install.packages("pgmm")  # Impl√©mentation du GMM
library(plm)
library(AER)
library(pgmm)

data("EmplUK", package = "plm")


# Sp√©cification du mod√®le Arellano-Bond (GMM) avec pgmm
gmm_model <- pgmm(formula |lag(log(BREAKFAST), 2:7),
  data = data,
  effect = "twoways",
  model = "twosteps"
)

# R√©sum√© du mod√®le
summary(gmm_model)

